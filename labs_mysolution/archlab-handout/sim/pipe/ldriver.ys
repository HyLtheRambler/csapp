#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
	iaddq $-8, %rdx
	jl handleRemainder

loopUnrolling8ways:
	mrmovq (%rdi), %rcx	# read val from src...
	mrmovq 8(%rdi), %r8
	mrmovq 16(%rdi), %r9
	mrmovq 24(%rdi), %r10
	mrmovq 32(%rdi), %r11
	mrmovq 40(%rdi), %r12
	mrmovq 48(%rdi), %r13
	mrmovq 56(%rdi), %r14

movAndJmp_1:
	rmmovq %rcx, (%rsi)
	andq %rcx, %rcx
	jle movAndJmp_2
	iaddq $1, %rax
	
movAndJmp_2:
	rmmovq %r8, 8(%rsi)
	andq %r8, %r8
	jle movAndJmp_3
	iaddq $1, %rax

movAndJmp_3:
	rmmovq %r9, 16(%rsi)
	andq %r9, %r9
	jle movAndJmp_4
	iaddq $1, %rax

movAndJmp_4:
	rmmovq %r10, 24(%rsi)
	andq %r10, %r10
	jle movAndJmp_5
	iaddq $1, %rax

movAndJmp_5:
	rmmovq %r11, 32(%rsi)
	andq %r11, %r11
	jle movAndJmp_6
	iaddq $1, %rax

movAndJmp_6:
	rmmovq %r12, 40(%rsi)
	andq %r12, %r12
	jle movAndJmp_7
	iaddq $1, %rax

movAndJmp_7:
	rmmovq %r13, 48(%rsi)
	andq %r13, %r13
	jle movAndJmp_8
	iaddq $1, %rax

movAndJmp_8:
	rmmovq %r14, 56(%rsi)
	andq %r14, %r14
	jle test
	iaddq $1, %rax

test:
	iaddq $64, %rdi
	iaddq $64, %rsi
	iaddq $-8, %rdx
	jge loopUnrolling8ways

handleRemainder: # -8 ~ -1 (0 ~ 7)

	iaddq $4, %rdx # -4 ~ 3
	jl handleRemainder_0to3

handleRemainder_4to7:
	iaddq $-2, %rdx # -2 ~ 1
	jl handleRemainder_4to5

handleRemainder_6to7:
	mrmovq 40(%rdi), %rcx
	je handleRemainder_6

	mrmovq 48(%rdi), %rcx
	jmp handleRemainder_7

handleRemainder_4to5:
	iaddq $1, %rdx

	mrmovq 32(%rdi), %rcx
	je handleRemainder_5

	mrmovq 24(%rdi), %rcx
	jmp handleRemainder_4


handleRemainder_0to3:
	iaddq $2, %rdx # -2 ~ 1 (0 ~ 3)

	jl handleRemainder_0to1

handleRemainder_2to3:
	
	mrmovq 8(%rdi), %rcx
	je handleRemainder_2

	mrmovq 16(%rdi), %rcx
	jmp handleRemainder_3

handleRemainder_0to1:
	iaddq $1, %rdx

	mrmovq (%rdi), %rcx
	je handleRemainder_1

	ret

handleRemainder_7:
	andq %rcx, %rcx
	rmmovq %rcx, 48(%rsi)
	mrmovq 40(%rdi), %rcx
	jle handleRemainder_6
	iaddq $1, %rax

handleRemainder_6:
	andq %rcx, %rcx
	rmmovq %rcx, 40(%rsi)
	mrmovq 32(%rdi), %rcx
	jle handleRemainder_5
	iaddq $1, %rax

handleRemainder_5:
	andq %rcx, %rcx
	rmmovq %rcx, 32(%rsi)
	mrmovq 24(%rdi), %rcx
	jle handleRemainder_4
	iaddq $1, %rax

handleRemainder_4:
	andq %rcx, %rcx
	rmmovq %rcx, 24(%rsi)
	mrmovq 16(%rdi), %rcx
	jle handleRemainder_3
	iaddq $1, %rax

handleRemainder_3:
	andq %rcx, %rcx
	rmmovq %rcx, 16(%rsi)
	mrmovq 8(%rdi), %rcx
	jle handleRemainder_2
	iaddq $1, %rax

handleRemainder_2:
	andq %rcx, %rcx
	rmmovq %rcx, 8(%rsi)
	mrmovq (%rdi), %rcx
	jle handleRemainder_1
	iaddq $1, %rax

handleRemainder_1:
	andq %rcx, %rcx
	rmmovq %rcx, (%rsi)
	jle Done
	iaddq $1, %rax

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad -2
	.quad -3
	.quad 4
	.quad 5
	.quad -6
	.quad -7
	.quad -8
	.quad -9
	.quad -10
	.quad -11
	.quad 12
	.quad -13
	.quad 14
	.quad 15
	.quad -16
	.quad 17
	.quad -18
	.quad 19
	.quad 20
	.quad -21
	.quad 22
	.quad -23
	.quad 24
	.quad 25
	.quad -26
	.quad -27
	.quad 28
	.quad -29
	.quad 30
	.quad -31
	.quad 32
	.quad 33
	.quad 34
	.quad -35
	.quad 36
	.quad 37
	.quad -38
	.quad 39
	.quad -40
	.quad 41
	.quad 42
	.quad 43
	.quad 44
	.quad -45
	.quad 46
	.quad 47
	.quad 48
	.quad -49
	.quad -50
	.quad -51
	.quad 52
	.quad 53
	.quad -54
	.quad -55
	.quad 56
	.quad -57
	.quad 58
	.quad -59
	.quad 60
	.quad -61
	.quad -62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
